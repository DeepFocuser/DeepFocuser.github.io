<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://wonygony-328412.du.r.appspot.com/query?id=ahF2fndvbnlnb255LTMyODQxMnIVCxIIQXBpUXVlcnkYgICA6NeHgQoM"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="Attention Is ALL You Need" /><meta name="author" content="JONGGON KIM" /><meta property="og:locale" content="en" /><meta name="description" content="Attention Is ALL You Need 논문 바로가기" /><meta property="og:description" content="Attention Is ALL You Need 논문 바로가기" /><link rel="canonical" href="https://deepfocuser.github.io/posts/transformer/" /><meta property="og:url" content="https://deepfocuser.github.io/posts/transformer/" /><meta property="og:site_name" content="DeepFocuser" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-10-06T20:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Attention Is ALL You Need" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@JONGGON KIM" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"JONGGON KIM"},"description":"Attention Is ALL You Need 논문 바로가기","url":"https://deepfocuser.github.io/posts/transformer/","headline":"Attention Is ALL You Need","dateModified":"2021-11-29T05:30:37+09:00","datePublished":"2021-10-06T20:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://deepfocuser.github.io/posts/transformer/"},"@type":"BlogPosting","@context":"https://schema.org"}</script><title>Attention Is ALL You Need | DeepFocuser</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="DeepFocuser"><meta name="application-name" content="DeepFocuser"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://wonygony-328412.du.r.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://wonygony-328412.du.r.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://github.com/DeepFocuser/DeepFocuser.github.io/blob/gh-pages/assets/img/avatar/avatar.jpg?raw=true" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">DeepFocuser</a></div><div class="site-subtitle font-italic">남겨 놓는 공간</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>홈</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>카테고리</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>태그</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>타임라인</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT ME</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://www.linkedin.com/in/kim-jonggon-37ba19120" aria-label="linkedin" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="https://github.com/DeepFocuser" aria-label="github" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/" aria-label="twitter" class="order-5" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['rlawhdrhs27','gmail.com'].join('@')" aria-label="email" class="order-6" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-7" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> 홈 </a> </span> <span>Attention Is ALL You Need</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="찾기..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >취소</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Attention Is ALL You Need</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> JONGGON KIM </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Oct 6, 2021, 8:00 PM +0900" >Oct 6<i class="unloaded">2021-10-06T20:00:00+09:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Mon, Nov 29, 2021, 5:30 AM +0900" >Nov 29<i class="unloaded">2021-11-29T05:30:37+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3434 words">19 min read</span> <span id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </span> views</div></div><div class="post-content"><blockquote><p><a href="https://arxiv.org/abs/1706.03762">Attention Is ALL You Need 논문 바로가기</a></p></blockquote><p>대학원에서 공부할 당시 자연어 처리 맛만 보고, 회사 다니고 나서는 자연어 처리쪽 업무 경험은 전무하다. 앞으로도 특별한 일이 없는 한 딱히 있을 것 같진 않지만… transformer가 자연어처리 외에 다른 분야에도 사용되는 경우도 많다고 하니( ex) DETR ), 리뷰를 해보자. 본 논문은 transformer Model 구조 파악이 목적이다. 본인은 컴퓨터 비전 관련한 일을 하기 때문에…</p><p>자세히 리뷰하든, 간단히 리뷰하든 나중에 결국은 잊어먹더라… 최대한 핵심만 남겨놓자.</p><h2 id="abstract">Abstract</h2><hr /><p>Rnn, Convolution Layer을 사용하지 않은 Encoder, Decoder 구조 즉, transformer를 제안한다. 영어-독어 번역, 영어-프랑스어 번역에서 가장 좋은 결과를 냈고, 다른 작업(English Constituency parsing)에서도 성공적으로 적용이 가능했다고 한다.</p><p>병렬화 학습 가능하고, 학습 시간 적게 걸리고, BLUE 지표에서 엄청 좋았다는등 자랑도 한다.</p><h2 id="introduction">Introduction</h2><hr /><p>Recurrent neural network 기반의 모델이 최신을 이끌어왔고, 적용범위를 넓히기 위한 노력들을 계속해왔다.</p><p>Recurrent model은 시간을 포함하는 특성때문에 병렬화를 어렵게 한다. 최근에는 factorization tricks 와 conditional computation 같은 기법으로 계산 효율성을 증가시켰다고 한다. conditional computation는 모델성능까지 증가시켰다고 한다. 그러나 여전히 시간을 계산한다는 근본적인 제약이 남아 있다.</p><p>Attention 메커니즘은 다양한 작업에서 강력한 시퀀스 모델링이나 변환 모델에서 필수적인 부분이고, 입력 또는 출력의 시퀀스의 거리에 관계 없이 종속성 모델링이 가능하게 한다. 모든 경우는 아니지만, 몇몇 경우에는 Attention 메커니즘이 Recurrent network와 함께 사용된다고 한다.(seq2seq with attention 같은 것을 말하는 듯 하다.)</p><h2 id="background">Background</h2><hr /><p>ByteNet 나 ConvS2S는 두 임의의 입력 또는 출력 위치의 신호를 연관시키는데 필요한 operation의 수가 위치간의 거리에 따라 증가한다. 이러한 점은 먼 위치사이 에서의 의존도를 학습하기 어렵게 만든다고 한다. 그런데 transformer는 operation의 수가 상수라고 한다. (Muiti-Head Attention 때문이라고 한다.)</p><blockquote><p>정확히 어떤의미인지는 와닿지 않으나, transformer가 입,출력간의 의존도를 학습하는데 있어서 ByteNet, ConvS2S와 같은 모델들보다 계산이 적게 들어간다는 의미인듯 하다.</p></blockquote><p>Self-attention은 시퀀스의 표현을 계산하기 위해 단일 시퀀스의 다른 위치들을 연관시키는 Attention 메커니즘이다.</p><p>End-to-End memory 네트워크는 recurrent 어텐션 메커니즘에 기반한다.</p><p>Transformer는 오로지 Self-attention에 의존한 첫번째 변환 모델이다.</p><h2 id="model-architecture">Model Architecture</h2><hr /><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1000 600'%3E%3C/svg%3E" data-proofer-ignore data-src="https://github.com/DeepFocuser/DeepFocuser.github.io/blob/gh-pages/post/transformer/transformer.PNG?raw=true" alt="Desktop View" width="1000" height="600" /></p><ul><li>Transformer 구조<ul><li>stacked self-attention<li>point-wise<li>fully connected layers</ul><li><h3 id="encoder-and-decoder-stacks">Encoder and Decoder Stacks</h3><ul><li><h4 id="encoder">Encoder</h4><ul><li>encoder는 6개의 동일한 층을 쌓은 구조<li>각 층은 2개의 sub-layer를 가지고 있음.<ul><li><p>첫번째 층 : multi-head self-attention mechanism</p><li><p>두번째 층 : position-wise fully connected feed-forward network</p></ul><li>residual connection 사용 / layer normalization 사용<li>각 sub-layer의 output : LayerNorm(x+Sublayer(x))<li>residual connection을 사용하기 위해 모든 sub-layer, embedding layers는 <code class="language-plaintext highlighter-rouge">512 차원의 output</code> 을 생성</ul><li><h4 id="decoder">Decoder</h4><ul><li>decoder도 encoder와 같이 6개의 동일한 층을 쌓은 구조<li>encoder의 sub-layer 2개에 + 1개의 sub-layer를 더 넣음(multi-head attention)<ul><li>encoder stack의 출력에 대해 multi-head-attention을 수행한다.</ul><li>residual connection 사용 / layer normalization 사용<li><code class="language-plaintext highlighter-rouge">modified self-attention sub-layer</code><ul><li>현재 위치가 다음 위치에 주목하는 것을 방지 하기 위한 장치<li>이 masking은 <code class="language-plaintext highlighter-rouge">output embeddings들이 한 위치씩 offset되어 있다는 사실과 결합되어</code> i위치에 대한 예측이 반드시 위치 i보다 작은 위치에서 알려진 출력에만 의존할 수 있도록 한다.<ul><li><code class="language-plaintext highlighter-rouge">무슨 말인지 와닿지 않는다.(1)</code> - 해결<ul><li>Transformer는 문장 행렬로 입력을 한꺼번에 받으므로 현재 시점의 단어를 예측하고자 할 때, 입력 문장 행렬로부터 미래 시점의 단어 까지도 참고할 수 있는 현상이 발생한다. 이 문제를 해결하기 위해 Transformer의 decoder는 현재 시점의 예측에서 현재 시점보다 미래에 있는 단어를 참고하지 못하도록 마스크를 씌워준다는 얘기이다. 자세한 설명은 <a href="https://wikidocs.net/31379">여기</a>를 보면 될 것 같다.<li><a href="https://github.com/DeepFocuser/Pytorch-Transformer/blob/main/core/model/InputLayer.py">코드와 설명 주석이 있는 링크</a><li><a href="https://github.com/DeepFocuser/Pytorch-Transformer/blob/main/core/model/decoder_mask.png">위 코드에서 생성한 mask 그림</a><ul><li>encoder와 decoder의 입력 문장에 <PAD> 토큰이 있는 경우 attention에서 제외해주는 mask도 같이 적용한 결과이다.</PAD><li> <PAD> 토큰의 경우에는 실질적인 의미를 가진 단어가 아니므로, Transformer에서는 Key의 경우에 <PAD> 토큰이 존재한다면 이에 대해서는 계산을 제외하도록 마스킹(Masking)을 해준다. </PAD></PAD></ul></ul></ul></ul></ul><li><h3 id="attention">Attention</h3><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1000 600'%3E%3C/svg%3E" data-proofer-ignore data-src="https://github.com/DeepFocuser/DeepFocuser.github.io/blob/gh-pages/post/transformer/attention.PNG?raw=true" alt="Desktop View" width="1000" height="600" /></p><p>attention 함수는 query와 key-value 쌍을 output으로 맵핑 하는 것으로 설명될 수 있다. 여기서 query, key, values 그리고 output은 모두 다 vector이다. 출력은 values의 가중치 합으로 계산되며. 여기서 각 value에 할당된 가중치들은 해당 key를 가진 query의 호환성 함수에 의해 계산된다. -&gt;(weight는 query, key로 만들고, 그 만들어진 weight를 value와 계산한다.)</p><ul><li><h4 id="scaled-dot-product-attention">Scaled Dot-Product Attention</h4><ul><li><p>입력은 $queries,keys : d_{k} 차원, values : d_{v} 차원으로 구성 된다.$ 모든 키를 사용하여 쿼리의 내적을 계산하고, $\sqrt{d_k}$ 로 나눈다. 그리고 values에 대한 가중치를 얻기 위해 softmax 함수를 적용한다.</p><li><p>실제로는, queries 세트에 대한 attention 함수를 동시에 계산하여 행렬 Q로 묶는다. 키와 값도 행렬 K와 V로 묶입니다. 출력 행렬을 다음과 같이 계산한다. \(Attention(Q, K, V) = softmax({QK^T \over \sqrt{d_k}})\)</p></ul><p>가장 많이 사용하는 attention 함수들로는 additive attention 함수, dot-product 함수가 있다. dot-product 함수는 scaling factor $1 \over \sqrt{d_k}$가 있다는 점 외에는 본 논문에서 사용한 알고리즘과 동일하다.</p><p>두 알고리즘은 비슷하지만, dot-product attention 함수가 실전에서 더 빠르고 공간 효율적이라고 한다.</p><li><h4 id="multi-head-attention">Multi-Head Attention</h4><p>$d_{model}-차원$의 keys, values, queries를 사용하여 single attention function 을 수행하는 대신, $d_{k}, d_{k}, d_{v}$차원에 대해 학습된 서로 다른 선형 프로젝션을 사용하여 queries, keys, values 를 h번 선형으로 투영하는 것이 좋다는 것을 발견했다. 이렇게 하면 $d_{v}-dimensional$ output values를 산출하는 attention function을 병렬적으로 수행할 수 있다. 이 값들은 concat 되고 한번더 투영되어, 최종적인 값을 결과로 뽑아낸다.(Figure 2 보라) Multi-head attention을 통해 모델이 서로 다른 위치에서 서로 다른 표현 하위 공간의 정보에 공동으로 주의를 기울일 수 있다. 하나의 attention head로, 평균을 내는 것은 공동으로 주의를 기울이는 것을 억제한다.</p><p>\(MultiHead(Q, K, V) = Concat(Head_{1}, ..., head_{h})W^O\) \(where Head_{i} = Attention(QW_{i}^Q, KW_{i}^K, VW_{i}^V)\)</p><p>여기서 projections 들은 파라미터 행렬들이다. \(W_{i}^Q \varepsilon R^{d_{model} X d_{k}}, W_{i}^K \varepsilon R^{d_{model} X d_{k}}, W_{i}^V \varepsilon R^{d_{model} X d_{v}} and W^O \varepsilon R^{hd_{v} X d_{model}}\)</p><p>h = 8 인 병렬 attention layer, heads를 사용했으며, 각각 $ d_{k} = d_{v} = {d_{model} \over h} = 64$ 이다.</p><li><h4 id="applications-of-attention-in-out-model">Applications of Attention in out Model</h4><ul><li>encoder-decoder attention layer안에서, queries 는 이전 decoder layer 에서, memory keys, values 는 encoder의 출력에서 온다. 이는 decoder의 모든 위치가 입력 sequence의 모든 위치들에 주의를 기울일 수 있게 하는 것을 가능하게 한다. seq2seq 모델안의 encoder-decoder attention 메커니즘을 흉내냈다.<li>encoder는 self-attention layers 들을 포함한다. self-attention layer에서 모든 keys, values, queries 는 같은 장소에서 오고, 이 경우에 encoder의 이전 layer의 output이다. encoder의 각 위치들은 encoder의 이전 layer의 모든 위치들에 주의를 기울일수 있다.<li>비슷하게, decoder의 self-attention layer는 decoder의 각 위치가 decoder의 해당 위치까지 그리고 그 위치를 포함하는 모든 위치에 주의를 기울일 수 있도록 한다. 자동 회귀 속성을 유지하려면 decoder에서 왼쪽으로의 정보 흐름을 방지해야 한다. 잘못된 연결에 해당하는 softmax 입력의 모든 값을 마스킹(-∞로 설정)하여 scaled dot-product Attention 내부에서 이것을 구현한다. (Figure 2를 보라.)<ul><li><code class="language-plaintext highlighter-rouge">무슨 말인지 와닿지 않는다.(2)</code>-해결<ul><li><code class="language-plaintext highlighter-rouge">무슨 말인지 와닿지 않는다.(1)</code> 의 해결 내용과 같다.</ul></ul></ul></ul><li><h3 id="position-wise-feed-forward-networks">Position-wise Feed-Forward Networks</h3><p>attention sub-layers 외’에도 encoder 및 decoder의 각 계층에는 각 위치에 개별적이고 동일하게 적용되는 fully connected feed-forward network 가 포함된다. 이것은 사이에 ReLU 활성화가 있는 두 개의 선형 변환으로 구성된다. \(FFN(x) = max(0, xW_{1} + b_{1})W_{2} + b_{2}\) 선형 변환은 다른 위치들에서 동일하지만, layer마다 다른 파라미터들을 사용한다.</p><li><h3 id="embeddings-and-softmax">Embeddings and Softmax</h3><p>다른 sequence 변환 모델과 비슷하게, 우리는 input tokens 과 output tokens를 $d_{model}$ 차원 벡터로 바꾸기 위해 학습된 embeddings 을 사용한다. 우리는 또한 decoder 출력을 예측된 next-token 확률로 바꾸기 위해 학습된 선형 변환과 softmax함수를 사용한다. 우리 모델에서는 2개의 embedding layers 와 pre-softmax(예측 softmax) 선형 변환 간에 같은 가중치 행렬을 공유한다. embedding layer에서는 $\sqrt{d_{model}}$을 가중치에 곱한다.</p><ul><li><code class="language-plaintext highlighter-rouge">코드를 봐야 알 것 같다.(3)</code> - 해결<ul><li><a href="https://github.com/DeepFocuser/Pytorch-Transformer/blob/main/core/model/InputLayer.py">코드와 설명 주석이 있는 링크</a><li>https://nlp.seas.harvard.edu/2018/04/03/attention.html 에 Shared Embeddings 이란 제목으로 설명되어 있다.</ul></ul><li><h3 id="positional-encoding">Positional Encoding</h3><p>transformer는 recurrence 와 convolution을 포함하고 있지 않기 때문에 모델이 시간 순서정보를 사용하게 하기 위해서, sequence의 토큰의 상대적 위치 또는 절대적 위치에 어떤 정보를 넣어줘야만 한다. 이를 위해서 encoder와 decoder stacks의 아랫부분의 input embeddings에 <code class="language-plaintext highlighter-rouge">positional encoding</code>이라는 것을 추가한다. embeddings과 <code class="language-plaintext highlighter-rouge">positional encoding</code>이 덧셈이 가능하게 하기 위해 <code class="language-plaintext highlighter-rouge">positional encoding</code> 은 embeddings과 같이 $d_{model}$ 차원을 가진다.</p><p>본 논문에서는 다른 주기를 가지는 sine, cosine 함수를 사용한다.</p>\[PE_{pos, 2i} = sin({position \over 10000^{2i \over d_{model}}})\] \[PE_{pos, 2i+1} = cos({position \over 10000^{2i \over d_{model}}})\]<ul><li><code class="language-plaintext highlighter-rouge">여기 내용을 이해가기가 쉽지 않다.(4)</code><ul><li>seq2seq 모델같은 경우는 RNN을 사용하므로, 입력 자체에 시간 속성이 부여되어 있다. 그런데 transformer같은 경우는 그런게 없다. 그래서 transformer의 encoder, decoder에 시간 속성을 부여하기 위해서 위의 sin, cos 함수를 더해주는 것이다.<li><a href="https://github.com/DeepFocuser/Pytorch-Transformer/blob/main/core/model/InputLayer.py">코드와 설명 주석이 있는 링크</a><li><a href="https://github.com/DeepFocuser/Pytorch-Transformer/blob/main/core/model/pe.png">위 코드에서 생성한 Positional Encoding 그림</a></ul></ul></ul></ul><p>아래의 내용부터는 그렇게 중요하다고 생각되지 않는다. 따라서 무슨내용을 다뤘는지만 간단히 설명하고 넘어간다.</p><h2 id="why-self-attention">Why Self-Attention</h2><hr /><p>왜 self-Attention을 사용했는지에 대해 말하고 있고, 몇가지 장점을 설명하고 있다.(계산량, 병렬화, long-range dependencies 학습)</p><p>부수적인 이익으로 self-attention은 해석가능한 모델을 산출해낸다고 한다.</p><h2 id="training">Training</h2><hr /><ul><li><h3 id="training-data-and-batching">Training Data and Batching</h3><p>데이터셋에 대한 설명</p><li><h3 id="hardward-and-schedule">Hardward and Schedule</h3><p>어떤 GPU룰 썼고, 어떻게 학습을 했고, 어떤 hyperparameter를 사용했는지에 대한 설명</p><li><h3 id="optimizer">Optimizer</h3><p>어떤 Optimizer를 사용했고, 학습률은 어떻게 설정했는지에 대한 설명</p><li><h3 id="regularization">Regularization</h3><p>학습할때 사용한 3가지 type의 regularization 설명</p></ul><h2 id="results">Results</h2><hr /><ul><li><h3 id="machine-translation">Machine Translation</h3><li><h3 id="model-variations">Model Variations</h3><li><h3 id="english-constituency-parsing">English Constituency Parsing</h3></ul><h2 id="conclusion">Conclusion</h2><hr /><p>번역 작업에서 Transformer은 RNN or CONV layer 기반의 아키텍쳐보다 훨씬 더 빠르게 학습이 가능했음. WMT2014 데이터셋 기반 영어-독어 번역, 영어-프랑스어 번역 작업에서 가장 좋은 결과를 성취할 수 있었다.</p><p>Transformer 모델을 input-output 구조를 가지고 있는 문제들(images, audio, video)에 확장할 계획이다.</p><h2 id="code">Code</h2><hr /><p>논문을 리뷰하며 잘 이해가 되지 않는 부분들이 있었다.(표시해 놓음) 이제 코드를 구현하면서 내가 제대로 이해하지 못한 부분을 채워나가는 시간이 필요할 것 같다.</p><ul><li>며칠에 걸쳐서 독일어-영어 번역기 Transformer 모델 구현을 완료했다. 역시 논문을 읽는 것과 구현 사이에는 엄청난 괴리가 있다. 수많은 사이트들을 참고했고, 하나하나 직접 구현했다. 그 결과는 <a href="https://github.com/DeepFocuser/Pytorch-Transformer">여기 내 깃허브 저장소</a>에 있다. 상세한 설명과 참고 자료등을 주석으로 달아놨으니 누군가에게 도움이 되길바란다.</ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/ai/'>AI</a>, <a href='/categories/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC/'>자연어 처리</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/transformer/" class="post-tag no-text-decoration" >Transformer</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://deepfocuser.github.io/posts/transformer/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Attention Is ALL You Need - DeepFocuser&u=https://deepfocuser.github.io/posts/transformer/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://twitter.com/intent/tweet?text=Attention Is ALL You Need - DeepFocuser&url=https://deepfocuser.github.io/posts/transformer/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://telegram.me/share?text=Attention Is ALL You Need - DeepFocuser&url=https://deepfocuser.github.io/posts/transformer/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>최근 업데이트</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/transformer/">Attention Is ALL You Need</a><li><a href="/posts/maximum-bipartite-matching/">Maximum Bipartite Matching</a><li><a href="/posts/detr/">DETR set prediction loss</a><li><a href="/posts/hungarian-algorithm/">Hungarian algorithm</a><li><a href="/posts/bfsdfs/">BFS DFS</a></ul></div><div id="access-tags"> <span>태그</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/beam-search/">Beam Search</a> <a class="post-tag" href="/tags/bfs/">BFS</a> <a class="post-tag" href="/tags/ctc-loss/">CTC Loss</a> <a class="post-tag" href="/tags/detr/">DETR</a> <a class="post-tag" href="/tags/dfs/">DFS</a> <a class="post-tag" href="/tags/hungarian-algorithm/">Hungarian algorithm</a> <a class="post-tag" href="/tags/maximum-bipartite-matching/">Maximum Bipartite Matching</a> <a class="post-tag" href="/tags/optimal-bipartite-matching/">Optimal Bipartite Matching</a> <a class="post-tag" href="/tags/transformer/">Transformer</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">컨텐츠</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip></h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/beamsearch/"><div class="card-body"> <span class="timeago small" >Oct 7<i class="unloaded">2021-10-07T20:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Beam Search Decoder</h3><div class="text-muted small"><p> https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/ 를 참고 Beam Search Decoder Beam Search는 Greedy Search 알고리즘(k=1)을 확장한 것이며, output sequences 의 리스트를 반환한다. be...</p></div></div></a></div><div class="card"> <a href="/posts/ctcloss/"><div class="card-body"> <span class="timeago small" >Oct 2<i class="unloaded">2021-10-02T20:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CTC Loss의 이해</h3><div class="text-muted small"><p> https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c 를 참고 CTC Loss의 이해 진행중 ~</p></div></div></a></div><div class="card"> <a href="/posts/detr/"><div class="card-body"> <span class="timeago small" >Nov 23<i class="unloaded">2021-11-23T20:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>DETR set prediction loss</h3><div class="text-muted small"><p> DETR 논문 바로가기 DETR 논문을 읽었다. ‘vision 문제중 하나인 object detector를 Transformer로 풀었다 NMS도 필요없다. 또 panoptic segmentation 에까지 확장 가능하다.’ 라는 내용인데, 읽으면서 몇가지 의문이 들었다. 구현을 염두해둔 의문(positional encoding은 어떻게 코드...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/ctcloss/" class="btn btn-outline-primary" prompt="이전"><p>CTC Loss의 이해</p></a> <a href="/posts/beamsearch/" class="btn btn-outline-primary" prompt="다음"><p>Beam Search Decoder</p></a></div><div id="disqus_thread" class="pt-2 pb-2"><p class="text-center text-muted small"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://deepfocuser.github.io/posts/transformer/'; this.page.identifier = '/posts/transformer/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver(function (entries) { if(entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://deepfocuser.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] }); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { /* Disqus hasn't been loaded */ if (typeof DISQUS === "undefined") { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } const modeToggle = document.querySelector(".mode-toggle"); if (modeToggle !== null) { modeToggle.addEventListener('click', reloadDisqus); window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', reloadDisqus); } </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://github.com/DeepFocuser">DeepFocuser</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">태그</h4><a class="post-tag" href="/tags/beam-search/">Beam Search</a> <a class="post-tag" href="/tags/bfs/">BFS</a> <a class="post-tag" href="/tags/ctc-loss/">CTC Loss</a> <a class="post-tag" href="/tags/detr/">DETR</a> <a class="post-tag" href="/tags/dfs/">DFS</a> <a class="post-tag" href="/tags/hungarian-algorithm/">Hungarian algorithm</a> <a class="post-tag" href="/tags/maximum-bipartite-matching/">Maximum Bipartite Matching</a> <a class="post-tag" href="/tags/optimal-bipartite-matching/">Optimal Bipartite Matching</a> <a class="post-tag" href="/tags/transformer/">Transformer</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { let initTheme = "default"; if ($("html[mode=dark]").length > 0 || ($("html[mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://deepfocuser.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">아무것도 찾을 수 없습니다.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-EDTXS6BH94"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-EDTXS6BH94'); }); </script>
